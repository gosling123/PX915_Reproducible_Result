{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PX915 Individual Project Reproducible Result - Ben Gosling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules for Plasma Parameter Calculation and GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import epoch calculators\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import sdf\n",
    "from scipy import constants\n",
    "\n",
    "from Py_scripts.run_epoch import * # stores functions which aid in the running of epoch simulations\n",
    "from Py_scripts.sim_setup import * # stores functions which aid in the creation of setting up epoch runs\n",
    "\n",
    "# Gaussian process regression scripts\n",
    "from Py_scripts.gp import * # stores functions for performing GP regression for 1D input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = constants.mu_0\n",
    "pi = np.pi\n",
    "pico = 1e-12\n",
    "micron = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCH requires you to specify an output directory which stores the input file to set up the simulation and store the output files. The python function below is used to create a directory within epoch_surra and populate it with one of the example input decks in the input_decks directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set name of the output directory\n",
    "dir = 'Data_epoch'\n",
    "sub_dirs = [f'Data_{i}' for i in range(1, 11)]\n",
    "dirs = [f'Data_epoch/Data_{i}' for i in range(1,11)]\n",
    "# input file/setup used throughout the report\n",
    "input_file = 'example_input.deck'\n",
    "# set initial laser intensity in W/cm^2 (varies between 1e14 - 1e16 in the report)\n",
    "intensity = 4e15 # set initial laser intensity in W/cm^2 \n",
    "# set density scale length in m (varies between 300e-6 - 100e-6 in the report) \n",
    "dens_scale_len = 500 * micron\n",
    "# set the number of particles per cell (set to 2048 in the report)\n",
    "# set to 100 to save time\n",
    "ppc = 100\n",
    "\n",
    "# For this example input deck, the number of timesteps and grid \n",
    "# cells are fixed at 4001 and 6473 respectively (see in example_input_deck)\n",
    "nx = 6473\n",
    "timesteps = 4001\n",
    "\n",
    "t_end = 2.0 * pico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sub_dirs)):\n",
    "    epoch_sim_sub_dir(dir = dir, sub_dir= sub_dirs[i], input_file = input_file, I = intensity, Ln = dens_scale_len, ppc = ppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch_in_parrallel():\n",
    "    pool = Pool(processes=len(dirs))\n",
    "    pool.map(run_epoch, dirs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_epoch_in_parrallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_Ey_field(dir):\n",
    "        # create space-time electric field array\n",
    "        Ey = np.zeros((nx, timesteps))\n",
    "        for i in range(timesteps):\n",
    "            fname = f'{dir}/fields_'+str(i).zfill(4)+'.sdf'\n",
    "            data = sdf.read(fname, dict = True)\n",
    "            Ey[:, i] = data['Electric Field/Ey'].data\n",
    "        return Ey\n",
    "        \n",
    "def get_2D_Bz_field(dir):\n",
    "        # create space-time electric field array\n",
    "        Bz = np.zeros((nx, timesteps))\n",
    "        for i in range(timesteps):\n",
    "            fname = f'{dir}/fields_'+str(i).zfill(4)+'.sdf'\n",
    "            data = sdf.read(fname, dict = True)\n",
    "            Bz[:, i] = data['Magnetic Field/Bz'].data\n",
    "        return Bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsincFIR(omega_c,omega_s,M):\n",
    "    # cutoff frequency shoudl be a fraction of sampling frequency\n",
    "    ker = np.sinc((omega_c / omega_s) * (np.arange(M) - (M - 1)/2))\n",
    "    # Blackman window used for smooting filter\n",
    "    ker *= np.blackman(M)\n",
    "    # unit gain at zero frequency \n",
    "    ker /= np.sum(ker) \n",
    "    return ker\n",
    "\n",
    "def bandpass(w0,bw,omega_s,M):\n",
    "    # Angular frequency used for NIF Laser\n",
    "    omega = 5.36652868179e+15\n",
    "    w0 = w0 * omega\n",
    "    bw = bw * omega\n",
    "    # upper and lower bound frequencies of bandpass\n",
    "    ub = w0 + (bw / 2)\n",
    "    lb = w0 - (bw / 2)\n",
    "    # create high-pass filter with cutoff at the lower-bound\n",
    "    # inverse low-pass filter\n",
    "    hhpf = -1 * winsincFIR(lb,omega_s,M) \n",
    "    hhpf[(M - 1) // 2] += 1\n",
    "    # create low-pass filter with cutoff at the upper-bound\n",
    "    hlpf = winsincFIR(ub,omega_s,M)\n",
    "    # convolve the two into a band-pass filter\n",
    "    h = np.convolve(hlpf, hhpf)\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_signals(dir, laser = False):\n",
    "        # required fields\n",
    "        Ey = get_2D_Ey_field(dir) # Ey(x,t) field\n",
    "        Bz = get_2D_Bz_field(dir) # Bz(x,t) field\n",
    "\n",
    "        n,m = Ey.shape # array size\n",
    "        omega_0 = 1.0 # normalised laser frequency \n",
    "        omega_bw = 0.3 # bandswidth centred at laser frequency\n",
    "        T_end = t_end # sim end time\n",
    "        N = timesteps # number of time steps\n",
    "        dt = T_end/N # time step\n",
    "        omegaNyq = pi/dt # Nyquist Frequency\n",
    "        omega_s = 2*pi/dt # sampling frequency \n",
    "        M = 1001 # half length of the filter kernel (must be odd) \n",
    "\n",
    "        h = bandpass(omega_0,omega_bw,omegaNyq,M) #bandpass filter\n",
    "\n",
    "       \n",
    "        # Laser signals\n",
    "        Ey_laser = np.zeros((n, m))\n",
    "        Bz_laser = np.zeros((n, m))\n",
    "\n",
    "        # SRS signals\n",
    "        Ey_SRS = np.zeros((n, m))\n",
    "        Bz_SRS = np.zeros((n, m))\n",
    "\n",
    "        # Fill arrays with data\n",
    "        for i in range(n):\n",
    "            # laser signals\n",
    "            Ey_laser[i, :] = np.convolve(Ey[i,:],h,mode='same')\n",
    "            Bz_laser[i, :] = np.convolve(Bz[i,:],h,mode='same')\n",
    "            # SRS signals\n",
    "            Ey_SRS[i, :] = Ey[i,:] - Ey_laser[i,:]\n",
    "            Bz_SRS[i, :] = Bz[i,:] - Bz_laser[i,:]\n",
    "\n",
    "        if laser:    \n",
    "            return Ey_laser, Bz_laser\n",
    "        else:    \n",
    "            return Ey_SRS, Bz_SRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bsrs(dir, ncells = 10, refelctivity = True):\n",
    "    # get required field signals\n",
    "    Ey, Bz = get_filtered_signals(dir, laser = False)           \n",
    "    W_cm2 = 1e4 # Convert to W_cm2\n",
    "    factor = mu0*W_cm2 # Denominator of Sx\n",
    "    S = Ey*Bz/factor # poynting flux\n",
    "    # integrate/average over time at each grid point\n",
    "    sum_t = np.zeros(nx)\n",
    "    for i in range(timesteps):\n",
    "        sig = S[:,i]\n",
    "        indx = np.where(sig > 0) # only care for backward travelling flux\n",
    "        sig[indx] = 0\n",
    "        sum_t += sig\n",
    "    S_t_av = np.abs(sum_t)/timesteps\n",
    "    # for backward travelling signals, we want to average close to the left-hand boundary\n",
    "    sum_x = 0\n",
    "    for i in range(ncells):\n",
    "        sum_x += S_t_av[i]\n",
    "    S_av = sum_x/ncells\n",
    "    if refelctivity:\n",
    "        return S_av/intensity\n",
    "    else:\n",
    "        return S_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_data = np.array()\n",
    "for dir in dirs:\n",
    "    P = get_bsrs(dir, ncells = 10, refelctivity=True)\n",
    "    P_data = np.append(P_data, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_mean = np.mean(P_data)\n",
    "P_var = np.mean(P_data)\n",
    "P_err = 2.0*np.sqrt(P_var)\n",
    "\n",
    "print(f'Mean reflectivity = {P_mean} W/cm^2')\n",
    "print(f'Varaiance of reflectivity = {P_var}')\n",
    "print(f'Error in reflectivity = {P_err} W/cm^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Training_data/train_inputs.json'\n",
    "output_file = 'Training_data/train_outputs_mean.json'\n",
    "var_file = 'Training_data/train_outputs_var.json'\n",
    "train_frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = LPI_GP(input_file=input_file, output_file=output_file,\\\n",
    "            var_file=var_file, train_frac=train_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.set_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.optimise_noise_GP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.optimise_GP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.test_train_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star = np.geomspace(4e14, 4e15, 100)[:,None]\n",
    "Y_star, V_epi, V_noise = gp.GP_predict(X_star, get_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.exp(gp.get_input())\n",
    "Y = np.exp(gp.get_output())\n",
    "\n",
    "X_all = np.exp(read_json_file('Training_data/all_inputs.json'))\n",
    "Y_all = np.exp(read_json_file('Training_data/all_outputs.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 10]\n",
    "\n",
    "error_epi = 2.0*np.sqrt(V_epi)\n",
    "error_tot = 2.0*np.sqrt(V_epi + V_noise)\n",
    "\n",
    "Y_s = Y_star.flatten()\n",
    "X_s = X_star.flatten()\n",
    "\n",
    "plt.loglog(X_s, Y_s, color = 'blue', label = 'GP Mean')\n",
    "plt.fill_between(X_s, (Y_s-error_epi), (Y_s+error_epi), alpha = 0.3, color = 'cyan', label = 'Epistemic Error')\n",
    "plt.fill_between(X_s, (Y_s-error_tot), (Y_s+error_tot), alpha = 0.15, color = 'red', label = 'Total Error')\n",
    "plt.plot(X_all, Y_all, 'kx', color = 'red', label = 'All Samples', alpha = 0.8)\n",
    "plt.plot(X, Y, 'kx', color = 'blue', label = 'Mean Samples')\n",
    "plt.xlim(4e14, 4e15)\n",
    "plt.ylim(2e-3, 2e-1)\n",
    "\n",
    "plt.ylabel(r'Reflectivity - $\\mathcal{P}$')\n",
    "plt.xlabel(r'$I_{L} \\,\\, W/cm^{2}$')\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_star, V_epi, V_noise = gp.GP_predict(X_star = np.array([intensity])[:,None], get_var=True)\n",
    "error_epi = 2.0*np.sqrt(V_epi)\n",
    "error_noise = 2.0*np.sqrt(V_noise)\n",
    "error_tot = 2.0*np.sqrt(V_epi + V_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_diff_epi = (np.abs((error_epi - P_err))/P_err)*100\n",
    "# per_diff_noise = (np.abs((error_noise - P_err))/P_err)*100\n",
    "# per_diff_total = (np.abs((error_tot - P_err))/P_err)*100\n",
    "P_err = V_noise\n",
    "err_compare = [P_err, V_epi, V_noise, V_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scaled sensitivities\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(['Samaple Error', 'GP Epistemic Error', 'GP Noise Error', 'GP Total Error'], err_compare, 'o')\n",
    "ax.set_xticklabels(['Samaple Error', 'GP Epistemic Error', 'GP Noise Error', 'GP Total Error'], rotation=90)\n",
    "ax.set_ylabel(r'Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
